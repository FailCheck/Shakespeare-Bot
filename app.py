import streamlit as st
import torch
import torch.nn as nn
import numpy as np

# ---------------------------------------------------------
# [1] í˜ì´ì§€ ì„¤ì • (ë°˜ë“œì‹œ ë§¨ ì²˜ìŒì— ì™€ì•¼ í•¨)
# ---------------------------------------------------------
st.set_page_config(
    page_title="AI Shakespeare",
    page_icon="âœ’ï¸",
    layout="wide"  # í™”ë©´ì„ ë„“ê²Œ ì”ë‹ˆë‹¤
)

# ---------------------------------------------------------
# [2] ìŠ¤íƒ€ì¼ ê¾¸ë¯¸ê¸° (CSS) - ê¸€ì”¨ì²´ë‚˜ ë°•ìŠ¤ ëª¨ì–‘ ì˜ˆì˜ê²Œ
# ---------------------------------------------------------
st.markdown("""
<style>
    .stTextInput > div > div > input {
        font-size: 20px;
    }
    .main-text {
        font-family: 'Times New Roman', serif;
        font-size: 1.2rem;
        line-height: 1.6;
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        color: #1a1a1a;
    }
</style>
""", unsafe_allow_html=True)

# ---------------------------------------------------------
# [3] AI ëª¨ë¸ í´ë˜ìŠ¤ (ë³€ê²½ ì—†ìŒ)
# ---------------------------------------------------------
class Net(nn.Module):
    def __init__(self, input_dim, hidden_dim, layers):
        super(Net, self).__init__()
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, input_dim, bias=True)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = out.reshape(-1, out.shape[2])
        out = self.fc(out)
        return out

# ---------------------------------------------------------
# [4] ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ (ìºì‹œ ì‚¬ìš©)
# ---------------------------------------------------------
@st.cache_resource
def load_model():
    try:
        checkpoint = torch.load('shakespeare.pt', map_location=torch.device('cpu'))
    except FileNotFoundError:
        return None, None, None

    dic_size = checkpoint['dic_size']
    hidden_size = checkpoint['hidden_size']
    num_layers = checkpoint['num_layers']
    chars = checkpoint['chars']
    
    model = Net(dic_size, hidden_size, num_layers)
    model.load_state_dict(checkpoint['model'])
    model.eval()
    return model, chars, dic_size

model, chars, dic_size = load_model()

# ---------------------------------------------------------
# [5] ì‚¬ì´ë“œë°” (ì„¤ì • ë©”ë‰´)
# ---------------------------------------------------------
with st.sidebar:
    st.image("https://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Shakespeare.jpg/220px-Shakespeare.jpg", width=150)
    st.title("âš™ï¸ ì„¤ì • (Settings)")
    st.write("AI ì‘ê°€ì˜ ì„±ê²©ì„ ì¡°ì ˆí•˜ì„¸ìš”.")
    
    # ìŠ¬ë¼ì´ë”ë“¤ì„ ì‚¬ì´ë“œë°”ë¡œ ì´ë™
    temperature = st.slider("ğŸŒ¡ï¸ ì°½ì˜ì„± (Temperature)", 0.1, 2.0, 0.8, help="ë‚®ìœ¼ë©´ ì§„ì§€í•˜ê³ , ë†’ìœ¼ë©´ ì—‰ëš±í•´ì§‘ë‹ˆë‹¤.")
    length = st.slider("ğŸ“ ê¸€ ê¸¸ì´ (Length)", 100, 1000, 300, step=100)
    
    st.divider()
    st.caption("Created by **Jay Jeon**")
    st.caption("Powered by PyTorch & LSTM")

# ---------------------------------------------------------
# [6] ë©”ì¸ í™”ë©´ êµ¬ì„±
# ---------------------------------------------------------
st.title("âœ’ï¸ AI Shakespeare Writer")
st.subheader("ì¸ê³µì§€ëŠ¥ì´ ì…°ìµìŠ¤í”¼ì–´ì˜ ë¬¸ì²´ë¡œ ê¸€ì„ ì´ì–´ ì”ë‹ˆë‹¤.")

# í™”ë©´ì„ ì™¼ìª½(ì…ë ¥)ê³¼ ì˜¤ë¥¸ìª½(ì¶œë ¥)ìœ¼ë¡œ 6:4 ë¹„ìœ¨ë¡œ ë‚˜ëˆ”
col1, col2 = st.columns([1, 1])

# --- ì™¼ìª½: ì…ë ¥ë€ ---
with col1:
    st.info("ğŸ‘‡ ì²« ë§ˆë””ë¥¼ ë˜ì ¸ì£¼ì„¸ìš”.")
    user_input = st.text_input("ì…ë ¥ (ì˜ì–´):", "The king")
    
    if model is None:
        st.error("ğŸš¨ ëª¨ë¸ íŒŒì¼(shakespeare.pt)ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    generate_btn = st.button("âœï¸ ê¸€ì“°ê¸° ì‹œì‘", type="primary", use_container_width=True)

    # ì›ë¦¬ ì„¤ëª… (í¬íŠ¸í´ë¦¬ì˜¤ìš©)
    with st.expander("â„¹ï¸ ì´ AIëŠ” ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?"):
        st.markdown("""
        1. **ë°ì´í„°:** ì…°ìµìŠ¤í”¼ì–´ í¬ê³¡ 100ë§Œ ìë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.
        2. **ëª¨ë¸:** LSTM(Long Short-Term Memory) ì‹ ê²½ë§ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
        3. **êµ¬ì¡°:** 2ê°œì˜ ì¸µ(Layers)ì„ ìŒ“ì•„ ë¬¸ë§¥ì„ ê¹Šì´ ì´í•´í•©ë‹ˆë‹¤.
        4. **í•™ìŠµ:** M-series GPU ê°€ì†ì„ í†µí•´ í•™ìŠµë˜ì—ˆìŠµë‹ˆë‹¤.
        """)

# --- ì˜¤ë¥¸ìª½: ê²°ê³¼ì°½ ---
with col2:
    if generate_btn and model is not None:
        char_dic = {c: i for i, c in enumerate(chars)}
        input_str = user_input
        generated_text = input_str
        
        status_text = st.empty()
        progress_bar = st.progress(0)
        
        try:
            with torch.no_grad():
                for i in range(length):
                    x = [char_dic.get(c, 0) for c in input_str[-100:]] # ìµœê·¼ 100ê¸€ìë§Œ ë´„
                    
                    # One-hot encoding
                    x_one_hot = np.zeros((1, len(x), dic_size))
                    for t, char_idx in enumerate(x):
                        x_one_hot[0, t, int(char_idx)] = 1
                    
                    x_input = torch.tensor(x_one_hot, dtype=torch.float32)
                    output = model(x_input)
                    last_output = output[-1]
                    
                    prob = torch.softmax(last_output / temperature, dim=0).numpy()
                    char_index = np.random.choice(dic_size, p=prob)
                    
                    next_char = chars[char_index]
                    generated_text += next_char
                    input_str += next_char
                    
                    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ (ë„ˆë¬´ ë¹ ë¥´ë©´ ì •ì‹ ì—†ìœ¼ë‹ˆ 10ê¸€ìë§ˆë‹¤ ê°±ì‹ )
                    if i % 10 == 0:
                        progress_bar.progress((i + 1) / length)
                        status_text.text(f"ì§‘í•„ ì¤‘... {i+1}/{length}ì")

            progress_bar.empty()
            status_text.empty()
            
            # ê²°ê³¼ ì˜ˆì˜ê²Œ ë³´ì—¬ì£¼ê¸°
            st.success("ì‘ì„± ì™„ë£Œ!")
            st.markdown(f'<div class="main-text">{generated_text}</div>', unsafe_allow_html=True)
            
        except Exception as e:
            st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")