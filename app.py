import streamlit as st
import torch
import torch.nn as nn
import numpy as np

# ---------------------------------------------------------
# 1. AI ëª¨ë¸ ì„¤ê³„ë„ (í•™ìŠµ ì½”ë“œì™€ ë˜‘ê°™ì•„ì•¼ í•¨!)
# ---------------------------------------------------------
class Net(nn.Module):
    def __init__(self, input_dim, hidden_dim, layers):
        super(Net, self).__init__()
        # ì¸µ ê°œìˆ˜(layers)ë¥¼ ë³€ìˆ˜ë¡œ ë°›ë„ë¡ ìˆ˜ì •!
        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers=layers, batch_first=True)
        self.fc = nn.Linear(hidden_dim, input_dim, bias=True)

    def forward(self, x):
        out, _ = self.lstm(x)
        out = out.reshape(-1, out.shape[2])
        out = self.fc(out)
        return out

# ---------------------------------------------------------
# 2. ì›¹ì‚¬ì´íŠ¸ í™”ë©´ êµ¬ì„±
# ---------------------------------------------------------
st.title("âœ’ï¸ AI Shakespeare Writer (Pro)")
st.caption("100ë§Œ ìì˜ ì…°ìµìŠ¤í”¼ì–´ ì „ì§‘ì„ í•™ìŠµí•œ 2ì¸µì§œë¦¬ LSTM ëª¨ë¸ì…ë‹ˆë‹¤.")

# ---------------------------------------------------------
# 3. ë‡Œ(.pt) ë¶ˆëŸ¬ì˜¤ê¸°
# ---------------------------------------------------------
@st.cache_resource
def load_model():
    # 1. íŒŒì¼ ì½ê¸°
    try:
        # map_location=torch.device('cpu')ëŠ” í´ë¼ìš°ë“œ(CPU)ì—ì„œ ëŒë¦¬ê¸° í•„ìˆ˜!
        checkpoint = torch.load('shakespeare.pt', map_location=torch.device('cpu'))
    except FileNotFoundError:
        return None, None, None

    # 2. ì €ì¥ëœ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
    # í•™ìŠµí•  ë•Œ ì €ì¥í–ˆë˜ 'save_data' ë”•ì…”ë„ˆë¦¬ë¥¼ ì—¬ê¸°ì„œ í’‰ë‹ˆë‹¤.
    dic_size = checkpoint['dic_size']
    hidden_size = checkpoint['hidden_size']
    num_layers = checkpoint['num_layers'] # 2ì¸µì´ë¼ëŠ” ì •ë³´ë¥¼ ì—¬ê¸°ì„œ ê°€ì ¸ì˜´!
    chars = checkpoint['chars']
    
    # 3. ëª¨ë¸ í‹€ ë§Œë“¤ê¸°
    model = Net(dic_size, hidden_size, num_layers)
    
    # 4. ê¸°ì–µ ì‹¬ê¸° (ê°€ì¤‘ì¹˜ ë¡œë“œ)
    model.load_state_dict(checkpoint['model'])
    model.eval() # í‰ê°€ ëª¨ë“œ (ì„±ì í‘œ ë°›ì„ ì¤€ë¹„)
    
    return model, chars, dic_size

model, chars, dic_size = load_model()

# ---------------------------------------------------------
# 4. ê¸€ì“°ê¸° ê¸°ëŠ¥
# ---------------------------------------------------------
if model is None:
    st.error("ğŸš¨ 'shakespeare.pt' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤! Githubì— ì—…ë¡œë“œí–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
else:
    # ì‚¬ìš©ì ì…ë ¥
    user_input = st.text_input("ì˜ì–´ ë‹¨ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì²« ë§ˆë””ë¥¼ ë˜ì ¸ì£¼ì„¸ìš”)", "The king")
    # [ì¶”ê°€í•  ì½”ë“œ] ì°½ì˜ì„± ì¡°ì ˆ ìŠ¬ë¼ì´ë”
    # 0.1 ~ 2.0 ì‚¬ì´ì˜ ê°’ì„ ì¡°ì ˆ. ê¸°ë³¸ê°’ì€ 0.8
    temperature = st.slider("ì°½ì˜ì„± ì¡°ì ˆ (Temperature)", 0.1, 2.0, 0.8)

    if st.button("AI, ê¸€ì„ ì¨ì¤˜!"):
        # ê¸€ì -> ìˆ«ì ì‚¬ì „
        char_dic = {c: i for i, c in enumerate(chars)}
        
        # ì…ë ¥ê°’ ì²˜ë¦¬
        input_str = user_input
        if len(input_str) > 100: input_str = input_str[-100:] # ë„ˆë¬´ ê¸¸ë©´ ìë¦„

        # ê¸€ì“°ê¸° ì‹œì‘
        generated_text = input_str
        
        # ë¡œë”©ë°” í‘œì‹œ
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        try:
            with torch.no_grad():
                for i in range(200): # 200ê¸€ì ìƒì„±
                    # í˜„ì¬ ë¬¸ì¥ì„ ìˆ«ìë¡œ ë³€í™˜
                    x = [char_dic.get(c, 0) for c in input_str] # ëª¨ë¥´ëŠ” ê¸€ìëŠ” 0ë²ˆìœ¼ë¡œ ì²˜ë¦¬
                    x = torch.tensor([x], dtype=torch.float32) # [1, len, vocab_size] (One-hotì€ ìƒëµ, ì„ë² ë”©ì²˜ëŸ¼ ì²˜ë¦¬í•˜ê±°ë‚˜ ìˆ˜ì • í•„ìš”í•˜ì§€ë§Œ ì¼ë‹¨ ì§„í–‰)
                    # ìœ„ ë°©ì‹ì€ ì°¨ì› ì—ëŸ¬ ê°€ëŠ¥ì„± ë†’ìŒ. í•™ìŠµë•Œ One-hot í–ˆìœ¼ë¯€ë¡œ ì—¬ê¸°ì„œë„ í•´ì¤˜ì•¼ í•¨.
                    
                    # One-hot Encoding (ì•ˆì „í•˜ê²Œ ë‹¤ì‹œ êµ¬í˜„)
                    x_one_hot = np.zeros((1, len(input_str), dic_size))
                    for t, char_idx in enumerate(x[0]):
                        x_one_hot[0, t, int(char_idx)] = 1
                    
                    x_input = torch.tensor(x_one_hot, dtype=torch.float32)

                    # ì˜ˆì¸¡
                    output = model(x_input)
                    
                    # ë§ˆì§€ë§‰ ê¸€ìì˜ ì˜ˆì¸¡ê°’ ê°€ì ¸ì˜¤ê¸°
                    last_output = output[-1]
                    
                    # í™•ë¥ ë¡œ ë³€í™˜ (Softmax) ë° ìƒ˜í”Œë§
                    prob = torch.softmax(last_output / temperature, dim=0).numpy()
                    
                    # ì•½ê°„ì˜ ë¬´ì‘ìœ„ì„± ì¶”ê°€ (Temperature) - ë„ˆë¬´ ë»”í•œ ë§ë§Œ ì•ˆ í•˜ê²Œ
                    char_index = np.random.choice(dic_size, p=prob)
                    
                    # ìˆ«ì -> ê¸€ì
                    next_char = chars[char_index]
                    generated_text += next_char
                    input_str += next_char # ë‹¤ìŒ ì˜ˆì¸¡ì„ ìœ„í•´ ë¶™ì„
                    
                    # ë¡œë”©ë°” ì—…ë°ì´íŠ¸
                    progress_bar.progress((i + 1) / 200)
                    status_text.text(f"ì§‘í•„ ì¤‘... ({i+1}/200ì)")

            st.success("ì‘ì„± ì™„ë£Œ!")
            st.markdown(f"### ğŸ“œ AIì˜ ì°½ì‘ë¬¼:\n> {generated_text}")
            
        except Exception as e:
            st.error(f"ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")